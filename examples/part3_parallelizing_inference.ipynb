{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d665c3a",
   "metadata": {},
   "source": [
    "#### Example: parallelizing PRI-T with chunking\n",
    "\n",
    "Here we'll test PRI-T's inference speed with two strategies:\n",
    "- a standard Viterbi search\n",
    "- \"chunking\" data into contiguous stretches and processing in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1ca5744",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2495473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example data from a closed-loop simulation run. Here we simulated 200 seconds (20 ms timebins) of closed-loop control after a nonstationarity occurs in the neural tuning matrix. The decoder is fixed, meaning there is now a mismatch between it and the neural tuning.\n"
     ]
    }
   ],
   "source": [
    "dat = loadmat('exampledat.mat')\n",
    "\n",
    "result =  dat['description'][0].replace('\\n', ' ')\n",
    "result = \"\\n\".join([re.sub(\"  +\",\" \",x.strip(\" \")) for x in \"\".join(result).split(\"\\n\")])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19005ac4",
   "metadata": {},
   "source": [
    "Let's measure the inference speed for our standard approach. We'll also measure the inferred and ground-truth target correlation here as a performance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92d28aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline target correlation: 0.8218927670060818 \n",
      " Baseline speed (sec):  6.469006299972534\n"
     ]
    }
   ],
   "source": [
    "from PRIT.prit_utils import generateTargetGrid, generateTransitionMatrix\n",
    "from PRIT.prit import HMMRecalibration\n",
    "import time\n",
    "\n",
    "gridSize  = 20      # number of rows/columns when discretizing screen\n",
    "stayProb  = 0.999  # probability that target just stays where it is at any given timestep\n",
    "vmKappa   = 2       # precision parameter for the von mises distribution.\n",
    "adjustKappa  = lambda x: 1 / (1 + np.exp(-1 * (x - 0.) * 32.)) # our kappa weighting function\n",
    "\n",
    "\n",
    "nStates                 = gridSize**2\n",
    "targLocs                = generateTargetGrid(gridSize = gridSize, is_simulated=True)\n",
    "stateTrans, pStateStart = generateTransitionMatrix(gridSize = gridSize, stayProb = stayProb)\n",
    "\n",
    "\n",
    "# create a PRI-T HMM object\n",
    "hmm = HMMRecalibration(stateTrans, targLocs, pStateStart, vmKappa, adjustKappa = adjustKappa)\n",
    "\n",
    "\n",
    "# record inference speed \n",
    "start = time.time()\n",
    "targStates, pTargState = hmm.predict([dat['cursorPos']], [dat['cursorVel']])\n",
    "baseline_speed   = time.time() - start \n",
    "inferredTargLoc  = hmm.targLocs[targStates.astype('int').flatten(),:]\n",
    "baseline_corr    = np.corrcoef(inferredTargLoc.flatten(), dat['targetPos'].flatten())[0,1]\n",
    "\n",
    "print('Baseline target correlation:', baseline_corr, '\\n',\n",
    "     'Baseline speed (sec): ', baseline_speed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8c3c16",
   "metadata": {},
   "source": [
    "On my machine, this takes 5-6 seconds. It may be faster/slower on your end. \n",
    "\n",
    "Now let's cut our data up into 30 second segments and run PRI-T in parallel on each. **Note**: the first time you run this block, numba has to compile the function. This will add a fixed overhead cost at the very start. After that compilation though, the result will be cached. Run the block twice to measure speed more accurately. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19b0b434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunked target correlation:  0.8263122185175749 \n",
      " Chunked speed (sec): 2.292280912399292\n"
     ]
    }
   ],
   "source": [
    "chunklens = 30 # length in seconds\n",
    "timestep  = 0.02 # sampling rate (bin size)\n",
    "parallel  = True  # tell HMMRecalibration object to parallelize across data\n",
    "\n",
    "\n",
    "# -----------------------------------\n",
    "chunksize  = chunklens // timestep\n",
    "num_chunks = dat['cursorVel'].shape[0] // chunksize \n",
    "chunked_cursorVel = np.array_split(dat['cursorVel'], num_chunks)\n",
    "chunked_cursorPos = np.array_split(dat['cursorPos'], num_chunks)\n",
    "\n",
    "start = time.time()\n",
    "targStates, pTargState = hmm.predict(chunked_cursorPos, chunked_cursorVel, parallel = parallel)\n",
    "chunk_speed      = time.time() - start \n",
    "\n",
    "inferredTargLoc  = hmm.targLocs[targStates.astype('int').flatten(),:]\n",
    "chunk_corr       = np.corrcoef(inferredTargLoc.flatten(), dat['targetPos'].flatten())[0,1]\n",
    "\n",
    "print('Chunked target correlation: ', chunk_corr, \n",
    "      '\\n Chunked speed (sec):', chunk_speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9b3698",
   "metadata": {},
   "source": [
    "After letting the function compile, we get the same target correlations but slightly faster speed (2.5 seconds versus 5 seconds for the baseline). \n",
    "\n",
    "Depending on how many threads you can spin out on your machine and your dataset size, you may get faster or slower speeds with different chunking sizes. I'd recommend using 10-30 second segments as a default and going from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d0733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Magneto (3.9)",
   "language": "python",
   "name": "mag-3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
